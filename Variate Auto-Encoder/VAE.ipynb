{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import idx2numpy\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 784\n",
    "hidden_dim = 200\n",
    "latent_dim = 20\n",
    "epochs = 30\n",
    "learning_rate = 0.00003\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, hidden_dim)\n",
    "        self.linear_mu = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.linear_logvar = nn.Linear(hidden_dim, latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.linear(x)\n",
    "        print(x.shape, np.isnan(h.detach().numpy()).any())\n",
    "        h = F.relu(h)\n",
    "        mu = self.linear_mu(h)\n",
    "        logvar = self.linear_logvar(h)\n",
    "        sigma = torch.exp(0.5 * logvar)\n",
    "        return mu, sigma\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.linear2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, z):\n",
    "        h = self.linear1(z)\n",
    "        h = F.relu(h)\n",
    "        h = self.linear2(h)\n",
    "        x_hat = F.sigmoid(h)\n",
    "        return h\n",
    "\n",
    "def reparameterize(mu, sigma):\n",
    "    eps = torch.randn_like(sigma)\n",
    "    z = mu + eps * sigma\n",
    "    return z\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(input_dim, hidden_dim, latent_dim)\n",
    "        self.decoder = Decoder(latent_dim, hidden_dim, input_dim)\n",
    "\n",
    "    def get_loss(self, x):\n",
    "        mu, sigma = self.encoder(x)\n",
    "        z = reparameterize(mu, sigma)\n",
    "        x_hat = self.decoder(z)\n",
    "        if np.isnan(mu.detach().numpy()).any():\n",
    "            print(\"|||\", mu[:10], sigma[:10], mu.shape, sigma.shape)\n",
    "            raise\n",
    "        batch_size = len(x)\n",
    "        L1 = F.mse_loss(x_hat, x, reduction='sum')\n",
    "        L2 = - torch.sum(1 + torch.log(sigma**2) - mu ** 2 - sigma ** 2)\n",
    "        return (L1 + L2) / batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n",
      "torch.Size([60000, 784]) False\n",
      "torch.Size([60000, 20])\n"
     ]
    }
   ],
   "source": [
    "for _ in range(100):\n",
    "    a = torch.FloatTensor(images).flatten(1,-1)\n",
    "    encoder = Encoder(input_dim, hidden_dim, latent_dim)\n",
    "    m, c = encoder(a)\n",
    "    print(c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = idx2numpy.convert_from_file('data/MNIST/raw/train-images.idx3-ubyte')  # shape: (num_images, rows, cols)\n",
    "labels = idx2numpy.convert_from_file('data/MNIST/raw/train-labels.idx1-ubyte')  # shape: (num_images, rows, cols)\n",
    "\n",
    "class mnistDataset(Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        self.x_data = torch.FloatTensor(images, requires_grad = True).flatten(1,-1)\n",
    "        self.y_data = torch.FloatTensor(labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.x_data[idx]\n",
    "        y = self.y_data[idx]\n",
    "\n",
    "        return x, y\n",
    "\n",
    "dataset = mnistDataset(images, labels)\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset, \n",
    "    batch_size = batch_size, \n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) False\n",
      "torch.Size([32, 784]) True\n",
      "||| tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "       grad_fn=<SliceBackward0>) tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "       grad_fn=<SliceBackward0>) torch.Size([32, 20]) torch.Size([32, 20])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[274], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, label \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m     10\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 11\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     loss_sum \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     13\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "Cell \u001b[0;32mIn[271], line 47\u001b[0m, in \u001b[0;36mVAE.get_loss\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39misnan(mu\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy())\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|||\u001b[39m\u001b[38;5;124m\"\u001b[39m, mu[:\u001b[38;5;241m10\u001b[39m], sigma[:\u001b[38;5;241m10\u001b[39m], mu\u001b[38;5;241m.\u001b[39mshape, sigma\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m     48\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(x)\n\u001b[1;32m     49\u001b[0m L1 \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmse_loss(x_hat, x, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "model = VAE(input_dim, hidden_dim, latent_dim)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss_sum = 0\n",
    "    cnt = 0\n",
    "\n",
    "    for x, label in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.get_loss(x)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_sum += loss.item()\n",
    "        cnt += 1\n",
    "\n",
    "    loss_avg = loss_sum / cnt\n",
    "    losses.append(loss_avg)\n",
    "    print(loss_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0008, -0.0330,  0.0316,  ..., -0.0192, -0.0342,  0.0032],\n",
      "        [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
      "        [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
      "        ...,\n",
      "        [ 0.0283, -0.0100,  0.0090,  ..., -0.0068, -0.0327,  0.0049],\n",
      "        [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
      "        [-0.0294,  0.0147,  0.0282,  ..., -0.0030, -0.0120,  0.0354]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0280,     nan,     nan,  0.0063,     nan,     nan,  0.0131,     nan,\n",
      "         0.0006,  0.0141,  0.0049,     nan, -0.0267,     nan,     nan, -0.0237,\n",
      "            nan,     nan,     nan,  0.0180, -0.0212,     nan, -0.0154, -0.0184,\n",
      "            nan,     nan, -0.0254,     nan,  0.0115, -0.0346, -0.0295, -0.0223,\n",
      "        -0.0227,  0.0221,     nan, -0.0281,     nan,     nan,     nan,  0.0283,\n",
      "            nan,     nan,  0.0226,  0.0076, -0.0317, -0.0058,  0.0324,     nan,\n",
      "        -0.0306, -0.0217,     nan,     nan, -0.0119, -0.0048,     nan,     nan,\n",
      "         0.0029,     nan,  0.0335,     nan, -0.0144,     nan,  0.0279,     nan,\n",
      "            nan,     nan,  0.0017,     nan,  0.0291,     nan, -0.0157, -0.0325,\n",
      "            nan,     nan,     nan,     nan, -0.0108,     nan, -0.0041,     nan,\n",
      "            nan,  0.0230,     nan,     nan,     nan, -0.0263,     nan,     nan,\n",
      "        -0.0020,  0.0163,     nan, -0.0153,  0.0320,     nan,     nan,     nan,\n",
      "        -0.0160, -0.0025, -0.0122,     nan,     nan, -0.0316,     nan,  0.0307,\n",
      "         0.0094,     nan,     nan, -0.0161,  0.0059, -0.0238,     nan,     nan,\n",
      "            nan,  0.0094,  0.0303, -0.0294,  0.0280, -0.0258,     nan,     nan,\n",
      "            nan, -0.0114,     nan, -0.0033,  0.0305, -0.0112,  0.0224,  0.0023,\n",
      "            nan, -0.0243, -0.0079,     nan,     nan,     nan,     nan,  0.0006,\n",
      "         0.0308, -0.0017,  0.0166, -0.0309,     nan,  0.0157,     nan,     nan,\n",
      "         0.0262,     nan,  0.0112,  0.0213,     nan, -0.0026,     nan,     nan,\n",
      "        -0.0361,     nan,     nan,     nan,  0.0312,     nan, -0.0096,  0.0069,\n",
      "        -0.0137, -0.0099,  0.0143,     nan, -0.0211,     nan,  0.0306,     nan,\n",
      "            nan,     nan,  0.0130,     nan,     nan,     nan,     nan, -0.0303,\n",
      "        -0.0219,  0.0014,     nan,     nan,  0.0222,     nan,  0.0099,  0.0002,\n",
      "        -0.0077,  0.0235,     nan, -0.0333,  0.0215, -0.0099,     nan,     nan,\n",
      "            nan,     nan,  0.0269,     nan,     nan, -0.0342,     nan,  0.0012],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0443,  0.0372, -0.0595,  ...,  0.0102,  0.0218,  0.0642],\n",
      "        [ 0.0362,  0.0308,  0.0091,  ..., -0.0587,  0.0446, -0.0025],\n",
      "        [-0.0182, -0.0712, -0.0156,  ...,  0.0325,  0.0619, -0.0076],\n",
      "        ...,\n",
      "        [-0.0040,  0.0452, -0.0021,  ...,  0.0186,  0.0393, -0.0268],\n",
      "        [ 0.0009,  0.0480,  0.0480,  ...,  0.0282, -0.0598, -0.0629],\n",
      "        [-0.0486, -0.0173, -0.0220,  ..., -0.0675,  0.0443, -0.0648]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0267, -0.0337,  0.0084, -0.0421,  0.0243, -0.0696,  0.0284,  0.0365,\n",
      "        -0.0224,  0.0328,  0.0290,  0.0364,  0.0321, -0.0438,  0.0015, -0.0110,\n",
      "         0.0530,  0.0612, -0.0610,  0.0409], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0570, -0.0704, -0.0164,  ..., -0.0628, -0.0587, -0.0163],\n",
      "        [-0.0666, -0.0116,  0.0450,  ..., -0.0225, -0.0332, -0.0031],\n",
      "        [ 0.0103,  0.0067, -0.0386,  ...,  0.0297, -0.0114, -0.0523],\n",
      "        ...,\n",
      "        [-0.0280, -0.0536, -0.0255,  ..., -0.0497,  0.0294, -0.0097],\n",
      "        [ 0.0105, -0.0632, -0.0471,  ..., -0.0559,  0.0471,  0.0679],\n",
      "        [-0.0235,  0.0509, -0.0662,  ...,  0.0647,  0.0228, -0.0446]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0251,  0.0513,  0.0417, -0.0038, -0.0091, -0.0240, -0.0525, -0.0369,\n",
      "        -0.0675, -0.0007, -0.0566,     nan,  0.0347, -0.0688, -0.0120,  0.0472,\n",
      "        -0.0260,  0.0589, -0.0650,  0.0409], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in model.encoder.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
